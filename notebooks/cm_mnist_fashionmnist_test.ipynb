{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "199a14f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "repo_dir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(repo_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e41dabb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from models.cm import ContinuousMixture, GaussianDecoder\n",
    "from torchvision.datasets import MNIST, FashionMNIST\n",
    "from utils.reproducibility import seed_everything\n",
    "from utils.datasets import UnsupervisedDataset\n",
    "import torchvision.transforms as transforms\n",
    "from models.nets import mnist_conv_decoder\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "gpus = None if device == 'cpu' else 1\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d778a9e",
   "metadata": {},
   "source": [
    "## Choose the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40edf521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset, dataset_name = FashionMNIST, 'fashion_mnist'\n",
    "dataset, dataset_name = MNIST, 'mnist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51765809",
   "metadata": {},
   "outputs": [],
   "source": [
    "transf = transforms.Compose([transforms.ToTensor()])\n",
    "batch_size = 128\n",
    "\n",
    "test = UnsupervisedDataset(dataset(root=repo_dir + '/data/', train=False, download=True, transform=transf))\n",
    "test_loader = DataLoader(test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c08ac28",
   "metadata": {},
   "source": [
    "## Load model (you should specify a path!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfc4a433",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/s3313093/venvs/my_env/lib/python3.10/site-packages/pytorch_lightning/utilities/parsing.py:208\n",
      "\tUserWarning: Attribute 'decoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['decoder'])`.\n"
     ]
    }
   ],
   "source": [
    "# Warning: The model should be Conv based\n",
    "\n",
    "path = '../logs/mnist_gaussian/FFM/latent_dim_16/num_bins_16384/version_1/checkpoints/best_model_valid-epoch=7.ckpt'\n",
    "# path = '../logs/mnist_gaussian/denominator_1/FFM/latent_dim_16/num_bins_16384/lightning_logs/version_0/checkpoints/best_model_valid-epoch=12.ckpt'\n",
    "model = ContinuousMixture.load_from_checkpoint(path).to(device)\n",
    "model.missing = False\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac01d561",
   "metadata": {},
   "source": [
    "## Compute LLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e385ed51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing test LL using 128 bins..\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m z, log_w \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39msampler(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComputing test LL using \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m bins..\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m n_bins)\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_w\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/venvs/my_env/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/s3313093/cm-tpm-main/models/cm.py:190\u001b[0m, in \u001b[0;36mContinuousMixture.eval_loader\u001b[0;34m(self, loader, z, log_w, seed, progress_bar, device)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    189\u001b[0m loader \u001b[38;5;241m=\u001b[39m tqdm(loader) \u001b[38;5;28;01mif\u001b[39;00m progress_bar \u001b[38;5;28;01melse\u001b[39;00m loader\n\u001b[0;32m--> 190\u001b[0m lls \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(x\u001b[38;5;241m.\u001b[39mto(device), z, log_w, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, seed\u001b[38;5;241m=\u001b[39mseed) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m loader], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lls) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(loader\u001b[38;5;241m.\u001b[39mdataset)\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m lls\n",
      "File \u001b[0;32m/scratch/s3313093/cm-tpm-main/models/cm.py:190\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    189\u001b[0m loader \u001b[38;5;241m=\u001b[39m tqdm(loader) \u001b[38;5;28;01mif\u001b[39;00m progress_bar \u001b[38;5;28;01melse\u001b[39;00m loader\n\u001b[0;32m--> 190\u001b[0m lls \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_w\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m loader], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lls) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(loader\u001b[38;5;241m.\u001b[39mdataset)\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m lls\n",
      "File \u001b[0;32m/scratch/s3313093/cm-tpm-main/models/cm.py:151\u001b[0m, in \u001b[0;36mContinuousMixture.forward\u001b[0;34m(self, x, z, log_w, k, seed)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m z \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    149\u001b[0m     z, log_w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler(seed\u001b[38;5;241m=\u001b[39mseed)\n\u001b[0;32m--> 151\u001b[0m log_prob_bins \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_w\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_chunks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m log_prob \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlogsumexp(log_prob_bins, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m log_prob_bins\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m==\u001b[39m (x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), z\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)) \u001b[38;5;129;01mor\u001b[39;00m log_prob_bins\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m==\u001b[39m (x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), k)\n",
      "File \u001b[0;32m/scratch/s3313093/cm-tpm-main/models/cm.py:237\u001b[0m, in \u001b[0;36mGaussianDecoder.forward\u001b[0;34m(self, x, log_w, z, k, missing, n_chunks)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m log_prob_bins_top_k\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     log_prob_bins \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([mse_loss(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_pass(z_chunk), x, k, missing) \u001b[38;5;28;01mfor\u001b[39;00m z_chunk \u001b[38;5;129;01min\u001b[39;00m z_chunks], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m log_prob_bins \u001b[38;5;241m+\u001b[39m log_w\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/scratch/s3313093/cm-tpm-main/models/cm.py:237\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m log_prob_bins_top_k\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     log_prob_bins \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([mse_loss(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz_chunk\u001b[49m\u001b[43m)\u001b[49m, x, k, missing) \u001b[38;5;28;01mfor\u001b[39;00m z_chunk \u001b[38;5;129;01min\u001b[39;00m z_chunks], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m log_prob_bins \u001b[38;5;241m+\u001b[39m log_w\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/scratch/s3313093/cm-tpm-main/models/cm.py:245\u001b[0m, in \u001b[0;36mGaussianDecoder.forward_pass\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_pass\u001b[39m(\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    242\u001b[0m     z: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m    243\u001b[0m ):\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearn_std:\n\u001b[0;32m--> 245\u001b[0m         mu_logvar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m         mu, logvar \u001b[38;5;241m=\u001b[39m mu_logvar\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    247\u001b[0m         mu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmu_activation(mu)\n",
      "File \u001b[0;32m~/venvs/my_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/my_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/venvs/my_env/lib/python3.10/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/venvs/my_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/my_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/venvs/my_env/lib/python3.10/site-packages/torch/nn/modules/conv.py:1162\u001b[0m, in \u001b[0;36mConvTranspose2d.forward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m   1151\u001b[0m num_spatial_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m   1152\u001b[0m output_padding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_padding(\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   1154\u001b[0m     output_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1159\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1160\u001b[0m )\n\u001b[0;32m-> 1162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_transpose2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1167\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1168\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_padding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1169\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1170\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1171\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# if you run OOM, you may want to use n_chunks\n",
    "model.n_chunks = 32\n",
    "n_bins_list = [2**7, 2**8, 2**9, 2**10, 2**11, 2**12, 2**13, 2**14]\n",
    "            \n",
    "for n_bins in n_bins_list:\n",
    "    model.sampler.n_bins = n_bins\n",
    "    z, log_w = model.sampler(seed=42)\n",
    "\n",
    "    print('Computing test LL using %d bins..' % n_bins)\n",
    "    print(model.eval_loader(test_loader, z, log_w, device=device).mean().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d7a96b",
   "metadata": {},
   "source": [
    "## Sample from CMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbe45b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00798975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 2, 28, 28])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[16, 1, 28, 28]' is invalid for input of size 25088",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m samples \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mnet(torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m16\u001b[39m, latent_dim)\u001b[38;5;241m.\u001b[39mto(device))\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(samples\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m----> 4\u001b[0m grid_img \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mmake_grid(\u001b[43msamples\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m)\u001b[49m, nrow\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m      5\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(grid_img\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m));\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[16, 1, 28, 28]' is invalid for input of size 25088"
     ]
    }
   ],
   "source": [
    "latent_dim = model.sampler.latent_dim\n",
    "samples = model.decoder.net(torch.randn(16, latent_dim).to(device)).detach().cpu()\n",
    "print(samples.shape)\n",
    "grid_img = torchvision.utils.make_grid(samples.view(16, 1, 28, 28), nrow=4)\n",
    "fig, ax = plt.subplots(1, figsize=(10, 10))\n",
    "plt.imshow(grid_img.permute(1, 2, 0));\n",
    "ax.set_yticklabels([]);\n",
    "ax.set_xticklabels([]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "395a8337",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..255.0].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 66.,  14.,  55.,  ..., 110.,  22.,  86.],\n",
      "          [ 80., 114., 204.,  ..., 147.,  77.,   7.],\n",
      "          [ 37., 182.,  22.,  ...,  55.,  41.,  35.],\n",
      "          ...,\n",
      "          [ 81., 141.,   5.,  ..., 190., 119., 144.],\n",
      "          [ 41., 254.,  14.,  ...,  60.,  55., 228.],\n",
      "          [  0., 143., 225.,  ...,   0.,   1.,   1.]]],\n",
      "\n",
      "\n",
      "        [[[ 41., 113.,  84.,  ..., 164.,  64.,  75.],\n",
      "          [ 16., 197., 132.,  ...,  91.,  83.,  10.],\n",
      "          [ 41., 131.,  14.,  ...,  11., 130., 165.],\n",
      "          ...,\n",
      "          [ 63.,  39., 215.,  ...,  53., 252.,  21.],\n",
      "          [ 65.,  24.,  22.,  ...,  25.,  41.,  87.],\n",
      "          [  0.,   0.,   1.,  ...,   0.,   0.,   1.]]],\n",
      "\n",
      "\n",
      "        [[[  3., 136.,  41.,  ...,   9., 112.,  16.],\n",
      "          [140.,  93.,  10.,  ...,  66.,  38., 161.],\n",
      "          [ 27.,  19., 168.,  ...,  30., 168., 147.],\n",
      "          ...,\n",
      "          [124., 196.,  88.,  ...,  97.,  50.,   1.],\n",
      "          [ 55.,  69.,  84.,  ...,   0., 130., 202.],\n",
      "          [251., 162.,  67.,  ...,   1.,   1.,   1.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 22., 208., 101.,  ..., 131.,  55., 254.],\n",
      "          [172.,  78.,  39.,  ..., 109.,  24., 106.],\n",
      "          [ 41.,  71.,  55.,  ...,  32.,  65., 253.],\n",
      "          ...,\n",
      "          [121.,   4.,  33.,  ...,  61.,  23., 231.],\n",
      "          [ 22.,  18., 112.,  ...,  58., 168.,  20.],\n",
      "          [ 17.,   0.,   0.,  ...,   0.,   0.,   0.]]],\n",
      "\n",
      "\n",
      "        [[[ 22., 181., 130.,  ...,  83.,  70., 245.],\n",
      "          [250.,   1., 152.,  ...,  31.,  49., 198.],\n",
      "          [170.,  30.,  55.,  ..., 155.,  66.,  79.],\n",
      "          ...,\n",
      "          [198.,  97., 167.,  ..., 251.,  49.,  51.],\n",
      "          [ 66.,  11.,   3.,  ..., 187., 112.,   0.],\n",
      "          [  0.,   0.,   1.,  ...,   0.,   0.,   0.]]],\n",
      "\n",
      "\n",
      "        [[[112.,  55.,  59.,  ..., 245.,  66., 206.],\n",
      "          [ 59.,  18.,  25.,  ...,  39., 103.,  47.],\n",
      "          [181.,  86.,   3.,  ..., 155.,  22., 210.],\n",
      "          ...,\n",
      "          [169.,  67.,  67.,  ...,  57., 134., 100.],\n",
      "          [181., 131.,  84.,  ..., 122., 181., 116.],\n",
      "          [  0., 106.,  31.,  ...,   1.,   0.,   1.]]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(-20.0, 0, ''),\n",
       " Text(0.0, 0, ''),\n",
       " Text(20.0, 0, ''),\n",
       " Text(40.0, 0, ''),\n",
       " Text(60.0, 0, ''),\n",
       " Text(80.0, 0, ''),\n",
       " Text(100.0, 0, ''),\n",
       " Text(120.0, 0, ''),\n",
       " Text(140.0, 0, '')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "latent_dim = model.sampler.latent_dim\n",
    "logits = model.decoder.net(torch.randn(16, latent_dim).to(device)).detach().cpu()  # [16, 256, 28, 28]\n",
    "\n",
    "# Sample from the categorical distribution over 256 classes\n",
    "probs = F.softmax(logits, dim=1)  # [16, 256, 28, 28]\n",
    "samples = torch.multinomial(probs.permute(0, 2, 3, 1).reshape(-1, 256), num_samples=1)  # [16*28*28, 1]\n",
    "samples = samples.view(16, 28, 28).unsqueeze(1).float() # normalize to [0,1] for visualization\n",
    "\n",
    "print(samples)\n",
    "# Plot\n",
    "grid_img = torchvision.utils.make_grid(samples, nrow=4)\n",
    "fig, ax = plt.subplots(1, figsize=(10, 10))\n",
    "plt.imshow(grid_img.permute(1, 2, 0))\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticklabels([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04fa3d29",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'CategoricalMixture' from 'models.mixtures' (/scratch/s3313093/cm-tpm-main/models/mixtures.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# tbd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmixtures\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CategoricalMixture\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39msampler\u001b[38;5;241m.\u001b[39mn_bins \u001b[38;5;241m=\u001b[39m n_components \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1024\u001b[39m\n\u001b[1;32m      5\u001b[0m z, log_w \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39msampler(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'CategoricalMixture' from 'models.mixtures' (/scratch/s3313093/cm-tpm-main/models/mixtures.py)"
     ]
    }
   ],
   "source": [
    "# tbd\n",
    "from models.mixtures import CategoricalMixture\n",
    "\n",
    "model.sampler.n_bins = n_components = 1024\n",
    "z, log_w = model.sampler(seed=42)\n",
    "mixture = CategoricalMixture(logits_p=model.decoder.net(z.to(device)), logits_w=log_w).to(device)\n",
    "\n",
    "# return_p=False results in binary images, unsure why\n",
    "samples = mixture.sample(16, return_p=False).detach().cpu()\n",
    "\n",
    "grid_img = torchvision.utils.make_grid(samples.view(16, 1, 28, 28), nrow=4)\n",
    "fig, ax = plt.subplots(1, figsize=(10, 10))\n",
    "plt.imshow(grid_img.permute(1, 2, 0));\n",
    "ax.set_yticklabels([]);\n",
    "ax.set_xticklabels([]);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
