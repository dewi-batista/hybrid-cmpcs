epoch,step,train_loss,valid_loss_epoch
0,389,,0.4094337224960327
0,389,1.0125916004180908,
1,779,,0.24053159356117249
1,779,0.3044189512729645,
2,1169,,0.1868276596069336
2,1169,0.22648777067661285,
3,1559,,0.18048031628131866
3,1559,0.19364182651042938,
4,1949,,0.1649473011493683
4,1949,0.17186695337295532,
5,2339,,0.16636186838150024
5,2339,0.15389272570610046,
6,2729,,0.15399298071861267
6,2729,0.14512373507022858,
7,3119,,0.1370648592710495
7,3119,0.1355247050523758,
8,3509,,0.1473947912454605
8,3509,0.12711569666862488,
9,3899,,0.13140912353992462
9,3899,0.11760410666465759,
10,4289,,0.12893028557300568
10,4289,0.11379395425319672,
11,4679,,0.12699565291404724
11,4679,0.10715283453464508,
12,5069,,0.13398073613643646
12,5069,0.10144487023353577,
13,5459,,0.13495036959648132
13,5459,0.09628220647573471,
14,5849,,0.12926463782787323
14,5849,0.09214705228805542,
15,6239,,0.1289643496274948
15,6239,0.08859720826148987,
16,6629,,0.1279299557209015
16,6629,0.08622684329748154,
