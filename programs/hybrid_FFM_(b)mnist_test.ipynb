{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2e96322",
   "metadata": {},
   "source": [
    "# Directory shenanigans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d11bf21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# 1. repo_dir used later\n",
    "repo_dir = os.path.abspath(os.path.join(os.path.abspath(\"\"), \"..\"))\n",
    "\n",
    "# 2. sys.path must be appended for importing modules\n",
    "sys.path.append(repo_dir)\n",
    "\n",
    "# 3. fix current working directory\n",
    "os.chdir(os.path.abspath(os.path.join(os.path.abspath(\"\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57474cee",
   "metadata": {},
   "source": [
    "# Import libaries + assign device (CPU/GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7782371",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.cm_hybrid import ContinuousMixture\n",
    "from models.lo_hybrid import bins_lo, fast_bins_lo\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from utils.reproducibility import seed_everything\n",
    "\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# assign device (cpu or gpu, if present)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc99b81",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16b6eb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose True for MNIST and False for binary MNIST\n",
    "use_mnist = False\n",
    "\n",
    "# create data directory (if not done already)\n",
    "data_dir = \"../data\"\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "# download MNIST into data directory (if not done already)\n",
    "mnist_test = datasets.MNIST(root=\"../data\", train=False, download=True)\n",
    "labels_mnist_test = mnist_test.targets\n",
    "\n",
    "# convert dataset to tensor\n",
    "mnist_test = mnist_test.data.view(10_000, 784).float()\n",
    "\n",
    "# define test set and binarise if use_mnist is False\n",
    "X_test = mnist_test if use_mnist else (mnist_test / 255 >= 0.5).float()\n",
    "y_test = labels_mnist_test\n",
    "\n",
    "# load val and test sets into dataloaders\n",
    "batch_size = 128\n",
    "test_loader = DataLoader(X_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f982315a",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d5d2e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/s3313093/cm-tpm-main/logs/bmnist/hybrid/latent_dim_32/num_bins_8192/lambda_0.80/version_0/checkpoints/best_model_valid-epoch=32.ckpt\n"
     ]
    }
   ],
   "source": [
    "# model hyperparams\n",
    "dataset = 'mnist' if use_mnist else 'bmnist'\n",
    "lamda = 0.8\n",
    "latent_dim = 32\n",
    "num_bins_trained = 8_192\n",
    "version_num = 0\n",
    "\n",
    "# load model\n",
    "model_path = glob.glob(repo_dir+f'/logs/{dataset}/hybrid/latent_dim_{latent_dim}/num_bins_{num_bins_trained}/lambda_{lamda:.2f}/version_{version_num}/checkpoints/*.ckpt')[0]\n",
    "model = ContinuousMixture.load_from_checkpoint(model_path).to(device)\n",
    "model.n_chunks = 32\n",
    "model.missing = False # this was True before, check if difference (hope not)\n",
    "model.eval(); # semi-colon to prevent printing model architecture\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bbd501",
   "metadata": {},
   "source": [
    "## Evaluate mean negative log-likelihood and classification accuracies (on full and missing data) over the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fbd0c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_accuracies(\n",
    "#     model,\n",
    "#     X_test,\n",
    "#     y_test,\n",
    "#     lower_power_bound,\n",
    "#     upper_power_bound,\n",
    "#     latent_opt,\n",
    "#     use_mnist,\n",
    "#     missing_rate,\n",
    "#     batch_size=512,\n",
    "#     seed=42,\n",
    "# ):\n",
    "#     accuracies = []\n",
    "#     n_bins_list = [2 ** k for k in range(lower_power_bound, upper_power_bound)]\n",
    "\n",
    "#     seed_everything(seed)\n",
    "#     test_lls = []\n",
    "#     for n_bins in n_bins_list:\n",
    "#         model.sampler.n_bins = n_bins\n",
    "#         # if latent_opt:\n",
    "#         #     z, log_w = bins_lo(model, n_bins, train_loader, valid_loader, max_epochs=20, lr=1e-3, patience=5, device=device)\n",
    "#         # else:\n",
    "#         #     z, log_w = model.sampler(seed=seed)\n",
    "#         z, log_w = model.sampler(seed=seed)\n",
    "\n",
    "#         all_ll = torch.zeros(len(X_test), 10)\n",
    "\n",
    "#         if missing_rate == 0.0:\n",
    "#             # If no missingness, we can evaluate log‐lik directly\n",
    "#             test_lls.append(-model.eval_loader(test_loader, z, log_w, device=device).mean().item())\n",
    "\n",
    "#         # ————— prepare a single mask for all digits —————\n",
    "#         if missing_rate != 0.0:\n",
    "#             model.missing = True\n",
    "#             # draw one mask of the same shape as X_test\n",
    "#             # so that the same entries are \"missing\" under every digit‐label hypothesis\n",
    "#             mask = torch.rand_like(X_test) < missing_rate\n",
    "#         else:\n",
    "#             mask = None\n",
    "\n",
    "#         for digit in range(10):\n",
    "#             # start from clean copy of X_test each time\n",
    "#             Xd = X_test.clone()\n",
    "\n",
    "#             # apply the pre–computed mask (if any) so it is identical for all digit loops\n",
    "#             if mask is not None:\n",
    "#                 Xd[mask] = float('nan')\n",
    "\n",
    "#             # overwrite label channels with this candidate digit\n",
    "#             if use_mnist:\n",
    "#                 Xd[:, -1] = digit\n",
    "#             else:\n",
    "#                 bitstring = [int(b) for b in bin(digit)[2:].zfill(4)]\n",
    "#                 Xd[:, -4:] = torch.tensor(bitstring, dtype=torch.float)\n",
    "\n",
    "#             loader = DataLoader(Xd, batch_size=batch_size, shuffle=False)\n",
    "#             ll_chunks = []\n",
    "#             with torch.no_grad():\n",
    "#                 for xb in loader:\n",
    "#                     xb = xb.to(device)\n",
    "#                     llb = model.forward(xb, z, log_w, k=None, seed=seed)\n",
    "#                     ll_chunks.append(llb.cpu())\n",
    "#             all_ll[:, digit] = torch.cat(ll_chunks, dim=0)\n",
    "\n",
    "#         # classification by maximum log‐likelihood\n",
    "#         preds = all_ll.argmax(dim=1)\n",
    "#         acc = (preds == y_test.squeeze()).float().mean().item()\n",
    "#         accuracies.append(acc)\n",
    "\n",
    "#     if latent_opt:\n",
    "#         return n_bins_list, accuracies, z\n",
    "\n",
    "#     return n_bins_list, accuracies, test_lls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3c3613",
   "metadata": {},
   "source": [
    "## Plot accuracies over the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3548f37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_rates = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.7, 0.8, 0.9, 0.95]\n",
    "# acc_dict = {k: [] for k in missing_rates}\n",
    "# test_lls = []\n",
    "\n",
    "# for missing_rate in missing_rates:\n",
    "#     n_bins_list, acc_list, test_lls_list = compute_accuracies(\n",
    "#         model=model,\n",
    "#         X_test=X_test,\n",
    "#         y_test=y_test,\n",
    "#         lower_power_bound=14,\n",
    "#         upper_power_bound=15, # reduce this to 9 to speed up debugging\n",
    "#         latent_opt=False,\n",
    "#         use_mnist=use_mnist,\n",
    "#         missing_rate=missing_rate,\n",
    "#     )\n",
    "#     if missing_rate == 0.0:\n",
    "#         test_lls = test_lls_list\n",
    "#     acc_dict[missing_rate] = acc_list\n",
    "\n",
    "# print(f\"latent_dim_{latent_dim}/n_bins_{num_bins_trained}/epoch_{int(model_path.split('epoch=')[-1].split('.', 1)[0])} - LAMBDA {lamda:.2f}\")\n",
    "# for i in range(len(n_bins_list)):\n",
    "#     n_bins = n_bins_list[i]\n",
    "#     str_to_print = f\"Mean NLL and Accuracy for {n_bins:5d} components: {test_lls[i]:8.4f}\"\n",
    "#     for missing_rate in missing_rates:\n",
    "#         str_to_print += f\" : {acc_dict[missing_rate][i]:.4f}\"\n",
    "#     print(str_to_print)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16ded86",
   "metadata": {},
   "source": [
    "# Monte Carlo estimator bars for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "968840cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from random import randint\n",
    "\n",
    "# missing_rates = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95]\n",
    "# acc_dict = {k: [] for k in missing_rates}\n",
    "# num_runs = 50 # each run takes ~30s w/ N=2^9 and ~?s w/ N=2^14\n",
    "\n",
    "# for run in range(num_runs):\n",
    "#     rand_seed = randint(1, 2 ** 32 - 2)\n",
    "#     for missing_rate in missing_rates:\n",
    "#         n_bins_list, acc_list, test_lls_list = compute_accuracies(\n",
    "#             model=model,\n",
    "#             X_test=X_test,\n",
    "#             y_test=y_test,\n",
    "#             lower_power_bound=8,\n",
    "#             upper_power_bound=9,\n",
    "#             latent_opt=False,\n",
    "#             use_mnist=use_mnist,\n",
    "#             missing_rate=missing_rate,\n",
    "#             seed=rand_seed,\n",
    "#         )\n",
    "#         acc_dict[missing_rate].append(acc_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c4d845c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # missing percentages\n",
    "# missing_rates = sorted(acc_dict)\n",
    "# missing_pct = [m * 100 for m in missing_rates]\n",
    "\n",
    "# # compute mean and std (%) for each missing rate\n",
    "# means_pct = np.array([np.mean(acc_dict[m]) * 100 for m in missing_rates])\n",
    "# stds_pct  = np.array([np.std(acc_dict[m], ddof=1) * 100 for m in missing_rates])\n",
    "# print(means_pct, stds_pct)\n",
    "\n",
    "# # upper and lower bounds\n",
    "# upper = means_pct + stds_pct\n",
    "# lower = means_pct - stds_pct\n",
    "\n",
    "# # just plotting things, not too important to understand\n",
    "# base_color = plt.cm.viridis(0.5)\n",
    "# plt.figure(figsize=(6, 4))\n",
    "# plt.fill_between(missing_pct, lower, upper, color=base_color, alpha=0.2) # shade region between the lower and upper lines\n",
    "# plt.plot(missing_pct, means_pct, color=base_color, linestyle='-', marker='o', markersize=4, linewidth=2.5, label='Mean accuracy') # mean line\n",
    "# plt.plot(missing_pct, upper, color=base_color, linestyle='--', linewidth=1) # upper line\n",
    "# plt.plot(missing_pct, lower, color=base_color, linestyle='--', linewidth=1) # lower line\n",
    "# plt.xlabel(\"Pixel values missing at random (%)\", fontsize=10)\n",
    "# plt.ylabel(\"Accuracy (%)\", fontsize=10)\n",
    "# plt.xticks(missing_pct, fontsize=9)\n",
    "# ax = plt.gca()\n",
    "# ax.spines['top'].set_visible(False)\n",
    "# ax.spines['right'].set_visible(False)\n",
    "# for spine in ['left', 'bottom']:\n",
    "#     ax.spines[spine].set_color('#888888')\n",
    "#     ax.spines[spine].set_linewidth(0.8)\n",
    "# y_min = lower.min()\n",
    "# y_min_tick = int(np.floor(y_min / 10) * 10)\n",
    "# ax.set_yticks(np.arange(y_min_tick, 101, 10))\n",
    "# ax.yaxis.grid(True, linestyle='--', linewidth=1.0, color='#bbbbbb')\n",
    "# ax.set_ylim(y_min, 100)\n",
    "# plt.yticks(fontsize=9)\n",
    "# plt.legend(loc='upper right', bbox_to_anchor=(1, 1.0085), frameon=True, edgecolor='#888888', facecolor='white', fontsize=8)\n",
    "# plt.tight_layout(pad=0.5)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e20d33d",
   "metadata": {},
   "source": [
    "# Display just NLLs (this is to speed up obtaining them if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e782cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins_list = [2 ** k for k in range(8, 15)]\n",
    "seed=42\n",
    "seed_everything(seed=seed)\n",
    "\n",
    "# model hyperparams\n",
    "dataset = 'mnist' if use_mnist else 'bmnist'\n",
    "latent_dim = 32\n",
    "num_bins_trained = 8_192\n",
    "version_num = 0\n",
    "for lamda in [0, 0.2, 0.4, 0.6, 0.8, 1]:\n",
    "    \n",
    "    # load model\n",
    "    model_path = glob.glob(repo_dir+f'/logs/{dataset}/hybrid/latent_dim_{latent_dim}/num_bins_{num_bins_trained}/lambda_{lamda:.2f}/version_{version_num}/checkpoints/*.ckpt')[0]\n",
    "    model = ContinuousMixture.load_from_checkpoint(model_path).to(device)\n",
    "    model.n_chunks = 32\n",
    "    model.missing = False # this was True before, check if difference (hope not)\n",
    "    model.eval(); # semi-colon to prevent printing model architecture\n",
    "\n",
    "    out = \"\"\n",
    "    for n_bins in n_bins_list:\n",
    "        model.sampler.n_bins = n_bins\n",
    "        z, log_w = model.sampler(seed=seed)\n",
    "        test_ll = -model.eval_loader(test_loader, z, log_w, device=device).mean().item()\n",
    "        # print(f\"Mean NLL for {n_bins:5d} components: {test_ll:6.2f}\")\n",
    "        out += f\"{test_ll:.2f} & \"\n",
    "    print(\"\\hline\")\n",
    "    print(f\"{lamda:.1f} & \" + out[:-3] + 2 * \"\\\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2030609a",
   "metadata": {},
   "source": [
    "# Plot accuracies for fixed lamda and varying number of bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2b0ea6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert to percentages\n",
    "# missing_rates_pct = [m * 100 for m in missing_rates]\n",
    "# perf_matrix_pct = (np.array([acc_dict[m] for m in missing_rates]) * 100).T\n",
    "\n",
    "# plt.figure(figsize=(6, 4))\n",
    "# for idx, temp in enumerate(n_bins_list):\n",
    "#     plt.plot(\n",
    "#         missing_rates_pct,\n",
    "#         perf_matrix_pct[idx],\n",
    "#         linestyle='--',      # dashed lines\n",
    "#         marker='o',\n",
    "#         markersize=4,\n",
    "#         linewidth=2.5,       # a bit thicker\n",
    "#         label=str(temp),\n",
    "#     )\n",
    "\n",
    "# # Axis labels\n",
    "# plt.xlabel(\"Pixel values missing at random (%)\", fontsize=10)\n",
    "# plt.ylabel(\"Accuracy (%)\", fontsize=10)\n",
    "\n",
    "# # X‐ticks\n",
    "# plt.xticks(missing_rates_pct, fontsize=9)\n",
    "\n",
    "# ax = plt.gca()\n",
    "# # Remove top/right spines\n",
    "# ax.spines['top'].set_visible(False)\n",
    "# ax.spines['right'].set_visible(False)\n",
    "# # Lighten left/bottom spines\n",
    "# for spine in ['left', 'bottom']:\n",
    "#     ax.spines[spine].set_color('#888888')\n",
    "#     ax.spines[spine].set_linewidth(0.8)\n",
    "\n",
    "# # Dynamic y‐axis: from min accuracy up to 100%\n",
    "# y_min = perf_matrix_pct.min()\n",
    "# y_min_tick = int(np.floor(y_min / 10) * 10)   # round down to nearest 10\n",
    "# ax.set_yticks(np.arange(y_min_tick, 101, 10))  # ticks every 10%\n",
    "# # Make horizontal grid lines more prominent\n",
    "# ax.yaxis.grid(True, linestyle='--', linewidth=1.0, color='#bbbbbb')\n",
    "# ax.set_ylim(y_min, 100)\n",
    "# plt.yticks(fontsize=9)\n",
    "\n",
    "# # Legend in top right with a box, shifted up slightly\n",
    "# plt.legend(\n",
    "#     loc='upper right',\n",
    "#     bbox_to_anchor=(1, 1.0085),  # move legend a bit higher\n",
    "#     frameon=True,\n",
    "#     edgecolor='#888888',\n",
    "#     facecolor='white',\n",
    "#     fontsize=8\n",
    "# )\n",
    "\n",
    "# plt.tight_layout(pad=0.5)\n",
    "# plt.savefig(f\"../results_hybrid/figures/lam_{lamda}_acc.pdf\")\n",
    "# plt.savefig(f\"../results_hybrid/figures/lam_{lamda}_acc.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380be9dc",
   "metadata": {},
   "source": [
    "# Plot accuracies for fixed number of bins and varying lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e5384d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lamdas = [0, 0.2, 0.4, 0.6, 0.8, 1]\n",
    "# missing_rates = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95]\n",
    "\n",
    "# acc_dict = {k: [] for k in lamdas}\n",
    "# for lamda in lamdas:\n",
    "    \n",
    "#     # model hyperparams\n",
    "#     dataset = 'mnist' if use_mnist else 'bmnist'\n",
    "#     latent_dim = 32\n",
    "#     num_bins_trained = 8_192\n",
    "#     version_num = 0\n",
    "\n",
    "#     # load model\n",
    "#     model_path = glob.glob(repo_dir+f'/logs/{dataset}/hybrid/latent_dim_{latent_dim}/num_bins_{num_bins_trained}/lambda_{lamda:.2f}/version_{version_num}/checkpoints/*.ckpt')[0]\n",
    "#     model = ContinuousMixture.load_from_checkpoint(model_path).to(device)\n",
    "#     # model.sampler.n_bins = 16_384 # this is done already in the compute_acc() function, unneeded\n",
    "#     model.n_chunks = 32\n",
    "#     model.missing = False\n",
    "#     model.eval(); # semi-colon to prevent printing model architecture\n",
    "\n",
    "#     for missing_rate in missing_rates:\n",
    "#         n_bins_list, acc_list, test_lls_list = compute_accuracies(\n",
    "#             model=model,\n",
    "#             X_test=X_test,\n",
    "#             y_test=y_test,\n",
    "#             lower_power_bound=14,\n",
    "#             upper_power_bound=15,\n",
    "#             latent_opt=False,\n",
    "#             use_mnist=use_mnist,\n",
    "#             missing_rate=missing_rate,\n",
    "#         )\n",
    "#         acc_dict[lamda].append(acc_list[0])\n",
    "\n",
    "# print(f\"latent_dim_{latent_dim}/n_bins_{num_bins_trained}\")\n",
    "# for lam in lamdas:\n",
    "#     str_to_print = f\"Accuracy for {lam:.1f}\"\n",
    "#     for i in range(len(missing_rates)):\n",
    "#         str_to_print += f\" : {acc_dict[lam][i]:.4f}\"\n",
    "#     print(str_to_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56afe7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert missing rates to percentages\n",
    "# missing_rates_pct = [m * 100 for m in missing_rates]\n",
    "\n",
    "# # Convert each λ’s accuracy‐list to percentages\n",
    "# lambda_dict_pct = {lam: (np.array(acc_dict[lam]) * 100) for lam in acc_dict}\n",
    "\n",
    "# # Sort λ’s so the legend always reads in ascending order\n",
    "# sorted_lambdas = sorted(lambda_dict_pct.keys())\n",
    "\n",
    "# # Sample one color per λ from a colormap\n",
    "# cmap = plt.cm.viridis\n",
    "# colors = cmap(np.linspace(0, 1, len(sorted_lambdas)))\n",
    "\n",
    "# plt.figure(figsize=(6, 4))\n",
    "# for idx, lam in enumerate(sorted_lambdas):\n",
    "#     acc_pct = lambda_dict_pct[lam]\n",
    "#     plt.plot(\n",
    "#         missing_rates_pct,\n",
    "#         acc_pct,\n",
    "#         # color=colors[idx],\n",
    "#         linestyle='--',\n",
    "#         marker='o',\n",
    "#         markersize=4,\n",
    "#         linewidth=2.5,\n",
    "#         label=f\"λ = {lam}\",\n",
    "#     )\n",
    "\n",
    "# # Axis labels\n",
    "# plt.xlabel(\"Pixel values missing at random (%)\", fontsize=10)\n",
    "# plt.ylabel(\"Accuracy (%)\", fontsize=10)\n",
    "\n",
    "# # X‐ticks\n",
    "# plt.xticks(missing_rates_pct, fontsize=9)\n",
    "\n",
    "# ax = plt.gca()\n",
    "# # Remove top/right spines\n",
    "# ax.spines['top'].set_visible(False)\n",
    "# ax.spines['right'].set_visible(False)\n",
    "# # Lighten left/bottom spines\n",
    "# for spine in ['left', 'bottom']:\n",
    "#     ax.spines[spine].set_color('#888888')\n",
    "#     ax.spines[spine].set_linewidth(0.8)\n",
    "\n",
    "# # Dynamic y‐axis: from min accuracy up to 100%\n",
    "# all_acc_values = np.concatenate([lambda_dict_pct[lam] for lam in sorted_lambdas])\n",
    "# y_min = all_acc_values.min()\n",
    "# y_min_tick = int(np.floor(y_min / 10) * 10)\n",
    "# ax.set_yticks(np.arange(y_min_tick, 101, 10))\n",
    "# ax.yaxis.grid(True, linestyle='--', linewidth=1.0, color='#bbbbbb')\n",
    "# ax.set_ylim(y_min, 100)\n",
    "# plt.yticks(fontsize=9)\n",
    "\n",
    "# # Legend in top right\n",
    "# plt.legend(\n",
    "#     loc='upper right',\n",
    "#     bbox_to_anchor=(1, 1.0085),\n",
    "#     frameon=True,\n",
    "#     edgecolor='#888888',\n",
    "#     facecolor='white',\n",
    "#     fontsize=8\n",
    "# )\n",
    "\n",
    "# plt.tight_layout(pad=0.5)\n",
    "# plt.savefig(f\"../results_hybrid/figures/acc_vary_lam_ld_{latent_dim}.pdf\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a66e0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert missing rates to percentages\n",
    "# missing_rates_pct = [m * 100 for m in missing_rates]\n",
    "\n",
    "# # Convert each λ’s accuracy‐list to percentages\n",
    "# lambda_dict_pct = {\n",
    "#     lam: (np.array(acc_dict[lam]) * 100)\n",
    "#     for lam in acc_dict\n",
    "# }\n",
    "\n",
    "# # Sort λ’s so the legend always reads in ascending order\n",
    "# sorted_lambdas = sorted(lambda_dict_pct.keys())\n",
    "\n",
    "# # Sample one color per λ from a colormap\n",
    "# cmap = plt.cm.viridis\n",
    "# colors = cmap(np.linspace(0, 1, len(sorted_lambdas)))\n",
    "\n",
    "# plt.figure(figsize=(6, 4))\n",
    "# for idx, lam in enumerate(sorted_lambdas):\n",
    "#     acc_pct = lambda_dict_pct[lam]\n",
    "#     plt.plot(\n",
    "#         missing_rates_pct,\n",
    "#         acc_pct,\n",
    "#         # color=colors[idx],\n",
    "#         linestyle='--',\n",
    "#         marker='o',\n",
    "#         markersize=4,\n",
    "#         linewidth=1.0,\n",
    "#         label=f\"λ = {lam}\",\n",
    "#     )\n",
    "\n",
    "# # Axis labels\n",
    "# plt.xlabel(\"Pixel values missing at random (%)\", fontsize=10)\n",
    "# plt.ylabel(\"Accuracy (%)\", fontsize=10)\n",
    "\n",
    "# # X‐ticks\n",
    "# # plt.xticks(missing_rates_pct, fontsize=9)\n",
    "\n",
    "# x_thresh = 31\n",
    "# ax = plt.gca()\n",
    "# ax.set_xticks(np.arange(0, x_thresh + 1, 10))\n",
    "# ax.set_xlim(0, x_thresh)\n",
    "# plt.xticks(fontsize=9)\n",
    "\n",
    "# ax = plt.gca()\n",
    "# # Remove top/right spines\n",
    "# ax.spines['top'].set_visible(False)\n",
    "# ax.spines['right'].set_visible(False)\n",
    "# # Lighten left/bottom spines\n",
    "# for spine in ['left', 'bottom']:\n",
    "#     ax.spines[spine].set_color('#888888')\n",
    "#     ax.spines[spine].set_linewidth(0.8)\n",
    "\n",
    "# # Dynamic y‐axis: from min accuracy up to 100%\n",
    "# all_acc_values = np.concatenate([lambda_dict_pct[lam] for lam in sorted_lambdas])\n",
    "# y_min = 89\n",
    "# y_min_tick = int(np.floor(y_min / 10) * 10)\n",
    "# ax.set_yticks(np.arange(y_min_tick, 101, 1))\n",
    "# ax.yaxis.grid(True, linestyle='--', linewidth=1.0, color='#bbbbbb')\n",
    "# ax.set_ylim(89.5, 97.5)\n",
    "# plt.yticks(fontsize=9)\n",
    "\n",
    "# # Legend in top right\n",
    "# plt.legend(\n",
    "#     loc='upper right',\n",
    "#     bbox_to_anchor=(1, 1.0085),\n",
    "#     frameon=True,\n",
    "#     edgecolor='#888888',\n",
    "#     facecolor='white',\n",
    "#     fontsize=8\n",
    "# )\n",
    "\n",
    "# plt.tight_layout(pad=0.5)\n",
    "# plt.savefig(f\"../results_hybrid/figures/acc_vary_lam_ld_{latent_dim}_zoomed.pdf\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72939ad7",
   "metadata": {},
   "source": [
    "## Evaluate sample quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bbb02c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAJOCAYAAACqbjP2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAUTElEQVR4nO3d244iSRIEUFj1//8y+1BqzWxtQxtRjsclz3kcTZFcIsEUagu/Px6Pxw0AgJf+M/sJAADsQGgCAAgITQAAAaEJACAgNAEABIQmAICA0AQAEBCaAAACQhMAQOBX+j/e7/e3H/zZYeMjjwUjPnHgvfXLSQyFgJydJgCAgNAEABAQmgAAAkITAEBAaAIACMTtuRFaRsz2bA1qDAHwLjtNAAABoQkAICA0AQAEhCYAgIDQBAAQEJoAAAJCEwBAQGgCAAgITQAAAaEJACAgNAEABIQmAIDARwf2AgDjXg2+7xo8bvD5P+w0AQAEhCYAgIDQBAAQEJoAAAJCEwBAQGgCAAg4cgBY0rM686sKNpxmpNZffUzBFY8WeMZOEwBAQGgCAAgITQAAAaEJACAgNAEABLTngCVpyXElXUNxu+6rUxt3dpoAAAJCEwBAQGgCAAgITQAAAaEJACAgNAEABBw5cFGVddCRqqw6OaO61lX1oFR4pXJAddcxBSP34u5HEdhpAgAICE0AAAGhCQAgIDQBAASEJgCAgPbcNyMNhsrWw7vXWEHH6+dnVv6MZreGnl1nhfeG83T8LlSv3dm/iyv9/tlpAgAICE0AAAGhCQAgIDQBAASEJgCAgPbcNyP/sr+jZTPSUhh5PPPiznTSZ1d9L3TcPye9/6uoXgfVz2G363fNkdv9N8ZOEwBAQGgCAAgITQAAAaEJACAgNAEABIQmAICAIwc2UV2hVY2mU1ed+d1rVF9nZae9zqscKzBi91r/yuw0AQAEhCYAgIDQBAAQEJoAAAJCEwBAYJv2nDZAj8rhpVzPSCtzdqurcv2ufC90tBRPNPu3Z/b1//YcnhlZbzusRTtNAAABoQkAICA0AQAEhCYAgIDQBAAQEJoAAALbHDmwcpW30o6Vba6levhu5b3tXuBKRtZ71z1y6r1opwkAICA0AQAEhCYAgIDQBAAQEJoAAALbtOeurquJcJWWIuNmDwmtvn7XddhT13pb9fqvrPzcPsVOEwBAQGgCAAgITQAAAaEJACAgNAEABIQmAICAIwcKGLLLrqqH7777WCOPV33vOFqAV7qGTe+o6/tjJXaaAAACQhMAQEBoAgAICE0AAAGhCQAgoD03yexmwdVbH3wZabWN/M3sda0BxSeM3CPvrtHqtdvVil3ZT94DO00AAAGhCQAgIDQBAASEJgCAgNAEABDQngutPGNn1wYDa6ts5owYuX9G2kzsaeXZnle5/gq/cZXfEwk7TQAAAaEJACAgNAEABIQmAICA0AQAEBCaAAACjhz4pnJI6cqVWNY3uz5fef0VqsmcpXqQ7Y7f45VDdruGWncfEVDNThMAQEBoAgAICE0AAAGhCQAgIDQBAAS0576pbBasPOSX9c1uglVef+UGEnuqbnHu+D0+cv3K53bFe9dOEwBAQGgCAAgITQAAAaEJACAgNAEABIQmAIDAJY8cqK5JVg4gnF0zh5+oHCBaeY2uYaT06Vhro3/T9XhdA3uveLTAM3aaAAACQhMAQEBoAgAICE0AAAGhCQAgcMn23CuVQyANKX2fltOZKu+F6gaUJut1zB6kO+K078TdfxftNAEABIQmAICA0AQAEBCaAAACQhMAQEBoAgAIbHPkQFftsrLyuEN9cjU7VmivZva6HvkuOK22TV91feQ6leuten2ufP/uwE4TAEBAaAIACAhNAAABoQkAICA0AQAEtmnPVQ7SHbmO9g18qW4tddw/7tHzVLcoR67z7vW7rNxQM7AXAOAChCYAgIDQBAAQEJoAAAJCEwBA4P4I/7n67DZApa5/oV/ZEhh5rJM+s2o/WQNXf1+r75+O2ZFX/8xe2aGxdGVdzXEydpoAAAJCEwBAQGgCAAgITQAAAaEJACAgNAEABLYZ2FupusI58niVFWh1ajpVH39ReUyAe4EVdK1DRwv0s9MEABAQmgAAAkITAEBAaAIACAhNAACBS7bnRmjlwJeVm6QwatXBuCPXqBwWz/+y0wQAEBCaAAACQhMAQEBoAgAICE0AAAGhCQAg4MiBbyqHh8KJ3AucqLKKX3lMwMjxAY4V+Bw7TQAAAaEJACAgNAEABIQmAICA0AQAENCe+0YzCMZpn8IYjbc92GkCAAgITQAAAaEJACAgNAEABIQmAICA0AQAEHDkAEdT4+3laIE6r9au95ldjQwgHn28dyXXt9MEABAQmgAAAkITAEBAaAIACAhNAACB+0O9CADgr+w0AQAEhCYAgIDQBAAQEJoAAAJCEwBAQGgCAAgITQAAAaEJACAgNAEABIQmAICA0AQAEBCaAAACQhMAQEBoAgAI/Jr9BE5wv9//+N8fj0fzM6HDs88bdjT6PeU+4DTJvWCnCQAgIDQBAASEJgCAgNAEABAQmgAAAtpzBbTkAOB8dpoAAAJCEwBAQGgCAAgITQAAAaEJACAgNAEABBw5AAAHeXUMjkHLP2OnCQAgIDQBAASEJgCAgNAEABAQmgAAAtpzBZ61EQzyhfU9u0+1jNjVq7Vrvf+MnSYAgIDQBAAQEJoAAAJCEwBAQGgCAAgITQAAAUcOFOg4WmCkQjr6eJXXgVEj1ejKOrWhp3TqWu/W7s/YaQIACAhNAAABoQkAICA0AQAEhCYAgID23CSVDYbZbYiu62vv7auriTYyPLty4LZhqIwaWSPWVT87TQAAAaEJACAgNAEABIQmAICA0AQAEBCaAAACjhwoMLv2WTnoccfrs47ZNf3Z15/9XUCv2UdMzL7+FdlpAgAICE0AAAGhCQAgIDQBAASEJgCAgPZcgdkNhsqWT9dgU3rNXqMjKtdVVxNPa6pvOPMKOl5PZSP0drNGf8pOEwBAQGgCAAgITQAAAaEJACAgNAEABI5oz81ude3eBvi3rnlxsz+znY00YyrXaHUzZ9WWzezrv+K5jTmtVbby9+jK6+An7DQBAASEJgCAgNAEABAQmgAAAkITAEBAaAIACNwfK3QTD3Va5dJS+XLa5/pM5cDa2Wtn5CgNn/NrV3l/RnQdbbDyUOsd10fyftppAgAICE0AAAGhCQAgIDQBAASEJgCAwBEDezvsOMyx8vqcaaT98upvZrd5Kp3WDGJM14DqLpUN1yveB3aaAAACQhMAQEBoAgAICE0AAAGhCQAgIDQBAAQcOVBg5JiAd+udK9SfVx3GyriRtbNjzXrEFevU/L/K7/G/Pd67Rq7f8Xt1MjtNAAABoQkAICA0AQAEhCYAgIDQBAAQ+Gh7bqRtdVJDa+XhpZWtC9Y3u+XT1bjragNWmj2km9dOG9g7ovK3fHd2mgAAAkITAEBAaAIACAhNAAABoQkAICA0AQAEPnrkwEm19qsckzB7mCSf0VX/7ajPrzxAdcTs69PrpO/YK65dO00AAAGhCQAgIDQBAASEJgCAgNAEABD4aHvuJF0tgdnNiqu0BPmMjpZc1xrdsYlHvdnNU9ZipwkAICA0AQAEhCYAgIDQBAAQEJoAAALac6GuJk3l7K7qGV3sq2MmXJeue2Hkb056n/ky0tYcMbst+op1/Q87TQAAAaEJACAgNAEABIQmAICA0AQAEBCaAAACjhwoMPtogXev8eo6r/7GMQX7qqwzd6m8R7pq27PfM+rN/ky7jssYfQ5XY6cJACAgNAEABIQmAICA0AQAEBCaAAAC27TnKhsE1e2B2cMMK1tthvyyipUbO+9+t6z8Wljbjg3X223+c/sUO00AAAGhCQAgIDQBAASEJgCAgNAEABAQmgAAAtscOdBVq++4/uhzqHwsxwfs64o1309a9bvFZ8nt1jegesQV16idJgCAgNAEABAQmgAAAkITAEBAaAIACHy0PTd7YO7VjTQoDP9dX+X7ukIzp3Lg9mlDstlT13fvs8fquq9XuBe72WkCAAgITQAAAaEJACAgNAEABIQmAICA0AQAEPjokQOVtdzZFfXT6vMdz3nH92UHldXglY//GBlkO3vNnVqzvoLK9bbjOhh5ziu/zk8dh2CnCQAgIDQBAASEJgCAgNAEABAQmgAAAh9tz81W2QzqauXs2Bii1+yWS1fjrnJIaPU98u51Vm4Z8WX2sGdrpNan3k87TQAAAaEJACAgNAEABIQmAICA0AQAEDi6PTfyr+e75uU9e24rNyhmNwtZQ/UafffxZl//dtOAupLqGWarrpFPzWo7jZ0mAICA0AQAEBCaAAACQhMAQEBoAgAICE0AAIH744J98er6ZOWQ3ZNq/acOGVa/fV9XndlRAO8bvRe9pz0D1r3PfZLPxk4TAEBAaAIACAhNAAABoQkAICA0AQAEftyeO7Uh9V1X4471abNwEu05+KI9BwBQRGgCAAgITQAAAaEJACAgNAEABIQmAIDAr58+wFWq8yMDR6/y3gDQz4DqfnaaAAACQhMAQEBoAgAICE0AAAGhCQAg8OP2HFpyAPRbuSV3arPPThMAQEBoAgAICE0AAAGhCQAgIDQBAASEJgCAgCMHJjHk989e1VFH3hvvMycaqXNb83SqPFrg1doduc5P7gU7TQAAAaEJACAgNAEABIQmAICA0AQAELg/VCoAAP7KThMAQEBoAgAICE0AAAGhCQAgIDQBAASEJgCAgNAEABAQmgAAAkITAEBAaAIACAhNAAABoQkAICA0AQAEhCYAgMCv9H+83++ffB7Q6vF4DP+te4GTjN4L7gNOk9wLdpoAAAJCEwBAQGgCAAgITQAAAaEJACAgNAEABIQmAICA0AQAEBCaAAACQhMAQEBoAgAICE0AAAGhCQAgIDQBAASEJgCAgNAEABAQmgAAAkITAEDg1+wnAFzb4/H443+/3+9v/f+v/qby+ozzXrM7O00AAAGhCQAgIDQBAASEJgCAgNAEABAQmgAAAo4cgAsbqe9X/80zI38zoutoA7xv7M9OEwBAQGgCAAgITQAAAaEJACAgNAEABLTn4AK6mmiV1xlptY1cv7LRZSAtt1ttw9TaWYudJgCAgNAEABAQmgAAAkITAEBAaAIACAhNAAABRw4cbHb9mnVUDtJ9tUYqH2/lYxLerYcb/ruGrgHVo89h5vVH7usrrl07TQAAAaEJACAgNAEABIQmAICA0AQAENCe20RXy6lj4CrrqG7CjXj3Ois853e5F9ZQvXY61tsKbVXr9x92mgAAAkITAEBAaAIACAhNAAABoQkAIKA9N8nsls/seV+VtD7Gdc3i6vqMKh+r8nVah2fqmD1Xff2OxzqZnSYAgIDQBAAQEJoAAAJCEwBAQGgCAAgITQAAAUcOfNDsaulIZXp2hXaEquy4kfeu628qVd8LjhZY2+zvpFfeXSMnvZYT2GkCAAgITQAAAaEJACAgNAEABIQmAICA9lyBkSZNRyPiis0Grm32vVh5fffvl672WGVzuGuQ7srNulPXtZ0mAICA0AQAEBCaAAACQhMAQEBoAgAICE0AAAFHDixmxzrmjs/5VKfWfP9tZPju7Nr6yHPeVfVrXfUogBXMHrB+pXX9m50mAICA0AQAEBCaAAACQhMAQEBoAgAIaM990EhLYeRvTm0p8L6T1sLs4buvvPs+n/S5/M2ur3VkvXW81is21FZmpwkAICA0AQAEhCYAgIDQBAAQEJoAAAJCEwBAwJED31RWlleoRsMKuoaEVlLnXkPlUQDVx8B0rJHZQ3lfueI9YqcJACAgNAEABIQmAICA0AQAEBCaAAAC2nPfVDYVuhoMI+0S+AStUKpVfo+NNJqrW9A7Nu5G2oin/v7YaQIACAhNAAABoQkAICA0AQAEhCYAgMA27bmV/5V+ZVOhcmYS/FbZsKxu2cw2+/uDeivPOuyabzrzsW63dZuFP2WnCQAgIDQBAASEJgCAgNAEABAQmgAAAkITAEBgmyMHrsLwXT6ha/101IxPrTLzedVHbHRcp+s5d9n9XrTTBAAQEJoAAAJCEwBAQGgCAAgITQAAgfsj/Gf2u/+L95Np3L3vJ+0S7+tzqw4j5bnRz8znc53v3qs0VpPXaacJACAgNAEABIQmAICA0AQAEBCaAAACQhMAQMDA3gIdwxFf1Td3rHZypsq1uHKde+XnRp9nn/er34TZa2Rk7Y68zlPZaQIACAhNAAABoQkAICA0AQAEhCYAgID23AeNtCRG2ghXH6a442vZQdf7XdnAGXnOs69Pvcp1sMLfzHysV664ru00AQAEhCYAgIDQBAAQEJoAAAJCEwBAQGgCAAg4cuCbrgrns8cbuc5Vap9XeZ2/za6vd9WWV7zG7Xa99bab6qG4lUNpuwb2rvxdcCo7TQAAAaEJACAgNAEABIQmAICA0AQAENimPTe7jVB9/XcbGdoLZ6pugnU0y2avxZFhqF337+z35kq6huKOqHxuI2u3+m+e6fpdXomdJgCAgNAEABAQmgAAAkITAEBAaAIACGzTnqv8l/grN5ZObRzwZ7Pnu1U30Sqv06X69TDf7JZcZaus+rVUNgtXeG7dTUk7TQAAAaEJACAgNAEABIQmAICA0AQAEBCaAAAC2xw5UKm65q1+zCrerUBX1/0ra8s7Hnkwe1As9aqr+JVr5LTjMjq+P0av85udJgCAgNAEABAQmgAAAkITAEBAaAIACFyyPfdK1/DQd6+zcuOBXis3TDqGgXY1WVcYYMraRtb77DVa2bhbuVVuYC8AwERCEwBAQGgCAAgITQAAAaEJACAgNAEABBw58E1XTXJ2HRNut/p1WPl4ht+yutlrcccjD3ZnpwkAICA0AQAEhCYAgIDQBAAQEJoAAALac8CSNFnhNWv3uU8NE7bTBAAQEJoAAAJCEwBAQGgCAAgITQAAAaEJACDgyAH+x6dqmhVGhlO+ej1wGuudE438Ln3qd8FOEwBAQGgCAAgITQAAAaEJACAgNAEABO4PdQsAgL+y0wQAEBCaAAACQhMAQEBoAgAICE0AAAGhCQAgIDQBAASEJgCAgNAEABD4L87EMf7G8xmNAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 600x600 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from random import sample\n",
    "\n",
    "decoder_arch = 'MLP'\n",
    "n_bins = 32\n",
    "model.sampler.n_bins = n_bins\n",
    "z, log_w = model.sampler(seed=42)\n",
    "logits_tensor = model.decoder.net(z.to(device))\n",
    "chosen_idxs = sample(range(n_bins), 9)\n",
    "\n",
    "# 3 by 3 figure of samples\n",
    "fig, axes = plt.subplots(3, 3, figsize=(6, 6))\n",
    "axes = axes.flatten()\n",
    "for ax, idx in zip(axes, chosen_idxs):\n",
    "    logits_sample = logits_tensor[idx]\n",
    "    if decoder_arch == 'tConv':\n",
    "        logits_permute = logits_sample.permute(1, 2, 0)\n",
    "        logits_flat = logits_permute.reshape(-1, logits_permute.shape[-1])\n",
    "        sampled_pixel_vals = torch.distributions.Categorical(logits=logits_flat).sample()\n",
    "        img = sampled_pixel_vals.view(28, 28).detach().cpu().numpy()\n",
    "    else:\n",
    "        probs = torch.sigmoid(logits_sample)\n",
    "        sample_flat = torch.bernoulli(probs)\n",
    "        img = sample_flat.view(28, 28).detach().cpu().numpy()\n",
    "\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"../results_hybrid/figures/samples/ld_{latent_dim}/lam_{lamda:.2f}_ld_{latent_dim}_9_samples.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d397b55",
   "metadata": {},
   "source": [
    "# Load training and validation (for latent opt.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5203a576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # download MNIST into data directory (if needed)\n",
    "# mnist_train_and_val = datasets.MNIST(root=\"../data\", train=True, download=True)\n",
    "\n",
    "# # assign labels\n",
    "# labels_mnist_train_and_val = mnist_train_and_val.targets\n",
    "\n",
    "# # convert datasets to tensors\n",
    "# mnist_train_and_val = mnist_train_and_val.data.view(60_000, 784).float()\n",
    "\n",
    "# # embed class label in final pixel(s) of training samples\n",
    "# for idx in range(mnist_train_and_val.shape[0]):\n",
    "#     label = labels_mnist_train_and_val[idx]\n",
    "#     if use_mnist:\n",
    "#         mnist_train_and_val[idx][-1] = label\n",
    "#         # bin_label = torch.tensor([int(d) for d in bin(label)[2:].zfill(4)]).float()\n",
    "#         # mnist_train_and_val[idx][-4:] = bin_label\n",
    "#     else:\n",
    "#         binary_label = 255 * torch.tensor([int(d) for d in bin(label)[2:].zfill(4)]).float()\n",
    "#         mnist_train_and_val[idx][-4:] = binary_label\n",
    "\n",
    "# # define train and validation\n",
    "# if use_mnist:\n",
    "#     X_train = mnist_train_and_val[0:50_000]\n",
    "#     X_val   = mnist_train_and_val[50_000::]\n",
    "# else: # if use_mnist is False then binarise\n",
    "#     X_train = (mnist_train_and_val[0:50_000] / 255 >= 0.5).float()\n",
    "#     X_val   = (mnist_train_and_val[50_000::] / 255 >= 0.5).float()\n",
    "\n",
    "# y_train = labels_mnist_train_and_val[0:50_000]\n",
    "# y_val   = labels_mnist_train_and_val[50_000::]\n",
    "\n",
    "# # load data into data loaders\n",
    "# batch_size = 128\n",
    "# train_loader = DataLoader(X_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "# valid_loader = DataLoader(X_val  , batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab79ca70",
   "metadata": {},
   "source": [
    "# Latent optimisation: test on full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f87479e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model_path)\n",
    "# # latent optimisation should really be done here to avoid doing it again for missing\n",
    "# bins_full, acc_full, z_opt = compute_accuracies(\n",
    "#     model=model,\n",
    "#     X_test=X_test,\n",
    "#     y_test=y_test,\n",
    "#     lower_power_bound=8,\n",
    "#     upper_power_bound=9,\n",
    "#     latent_opt=True,\n",
    "#     use_mnist=use_mnist,\n",
    "#     missing=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a3f33c",
   "metadata": {},
   "source": [
    "## Evaluate sample quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef9c65e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def reconstruct_image(grayscale_vector):\n",
    "#     image_data = grayscale_vector.reshape((28, 28))\n",
    "#     plt.imshow(image_data, cmap='gray')\n",
    "#     plt.axis('off')\n",
    "#     plt.show()\n",
    "\n",
    "# from random import randint\n",
    "\n",
    "# decoder_arch = 'MLP'\n",
    "# n_bins = 32\n",
    "# model.sampler.n_bins = n_bins\n",
    "# z, log_w = model.sampler(seed=42)\n",
    "# logits_tensor = model.decoder.net(z.to(device))\n",
    "# logits_sample = logits_tensor[randint(0, n_bins - 1)]\n",
    "\n",
    "# if decoder_arch == 'tConv':\n",
    "#     logits_permute = logits_sample.permute(1, 2, 0)\n",
    "#     logits_flat = logits_permute.reshape(-1, logits_permute.shape[-1])\n",
    "#     sampled_pixel_vals = torch.distributions.Categorical(logits=logits_flat).sample()\n",
    "#     reconstruct_image(sampled_pixel_vals.view(28, 28).detach().cpu())\n",
    "# else:\n",
    "#     probs = torch.sigmoid(logits_sample)\n",
    "#     sample = torch.bernoulli(probs)\n",
    "#     reconstruct_image(sample.detach().cpu())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
